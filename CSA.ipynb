{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(s,x,t):\n",
    "    if t:\n",
    "        print(s+':==============================\\n')\n",
    "        print(x,x.shape)\n",
    "        print('==============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customizedModule(nn.Module):\n",
    "    def __init(self):\n",
    "        super(customizedModule,self).__init()\n",
    "    def customizedLinear(self,in_dim,out_dim,activation=None,dropout=False):\n",
    "        c1 = nn.Sequential(nn.Linear(in_dim,out_dim))\n",
    "        nn.init.xavier_uniform_(c1[0].weight)\n",
    "        nn.init.constant_(c1[0].bias,0)\n",
    "        \n",
    "        if activation is not None:\n",
    "            c1.add_module(str(len(c1)),activation)\n",
    "        if dropout:\n",
    "            c1.add_module(str(len(c1)),nn.Dropout(p=self.args.dropout))  \n",
    "        return c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(customizedModule):\n",
    "    def __init__(self,dx,dq,mode):\n",
    "        super(CrossAttention,self).__init__()\n",
    "        self.w1 = self.customizedLinear(dx,dx)\n",
    "        self.w2 = self.customizedLinear(dq,dx)   \n",
    "        self.w1[0].bias.requires_grad = False\n",
    "        self.w2[0].bias.requires_grad = False\n",
    "        \n",
    "        # bias for add attention\n",
    "        self.wt = self.customizedLinear(dx,1)\n",
    "        self.wt[0].bias.requires_grad = False\n",
    "        self.bsa = nn.Parameter(torch.zeros(dx))  \n",
    "        # 'mul' or 'add'\n",
    "        self.mode = mode  \n",
    "        self.debug = False\n",
    "    def forward(self,x,q):\n",
    "        if self.mode is 'mul':     \n",
    "            # W(1)x W(2)c\n",
    "            wx = self.w1(x)\n",
    "            wq = self.w2(q)\n",
    "            wq = wq.unsqueeze(-2)    \n",
    "            describe('wx',wx,self.debug)\n",
    "            describe('wq',wq,self.debug)         \n",
    "            # <x,q>\n",
    "            p = wx*wq\n",
    "            describe('wx * wq',p,self.debug)               \n",
    "            # p = [a0,a1,a2...]\n",
    "            p = torch.sum(p,dim=-1,keepdim=True)\n",
    "            describe('p after sum dim = -1',p,self.debug)        \n",
    "            # softmax along row       \n",
    "            p = F.softmax(p,dim=-2)\n",
    "            describe('p sm(row)',p,self.debug)        \n",
    "            #p = torch.reshape(p,(p.size(0),-1))\n",
    "            return p\n",
    "        \n",
    "        elif self.mode is 'add':   \n",
    "            describe('x is',x,self.debug)\n",
    "            describe('q is',q,self.debug)\n",
    "            wx = self.w1(x)\n",
    "            wq = self.w2(q) \n",
    "            wq = wq.unsqueeze(-2)\n",
    "            describe('wx',wx,self.debug)\n",
    "            describe('wq',wq,self.debug)\n",
    "            describe('wx+wq',wx+wq,self.debug)\n",
    "            describe('bsa',self.bsa,self.debug)\n",
    "            describe('wx+wq+bsa',wx+wq+self.bsa,self.debug)\n",
    "            p = self.wt(wx+wq+self.bsa)\n",
    "            describe('wt',p,self.debug)  \n",
    "            p = F.softmax(p,dim = -2)\n",
    "            describe('sm',p,self.debug)\n",
    "            return p\n",
    "        else:\n",
    "            raise NotImplementedError('CrossAttention error:<mul or add>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# position wise feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(customizedModule):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = self.customizedLinear(d_in, d_hid) # position-wise\n",
    "        self.w_2 = self.customizedLinear(d_hid, d_in) # position-wise\n",
    "        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.w_2(F.relu(self.w_1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSA(customizedModule):\n",
    "    def __init__(self,args,dx,dq):\n",
    "        super(CSA,self).__init__()\n",
    "        self.args = args\n",
    "        self.dx = dx\n",
    "        self.dq = dq  \n",
    "        if self.args.csa_mode is 'mul':\n",
    "            self.crossAttention = CrossAttention(dx,dq,'mul')\n",
    "        elif self.args.csa_mode is 'add':\n",
    "            self.crossAttention = CrossAttention(dx,dq,'add')\n",
    "        else:\n",
    "            raise NotImplementedError('CSA->CrossAttention error')\n",
    "        \n",
    "        self.Wsa1 = self.customizedLinear(dx,dx)\n",
    "        self.Wsa2 = self.customizedLinear(dx,dx)\n",
    "        self.Wsa1[0].bias.requires_grad = False\n",
    "        self.Wsa2[0].bias.requires_grad = False\n",
    "        self.wsat = self.customizedLinear(dx,1)\n",
    "        self.bsa1 = nn.Parameter(torch.zeros(dx))  \n",
    "        self.bsa2 = nn.Parameter(torch.zeros(dx)) \n",
    "        \n",
    "        self.debug = False\n",
    "        self.PFN = PositionwiseFeedForward(dx,dx)\n",
    "    def forward(self,x,c):\n",
    "        # x(batch,seq_len,word_dim) c(batch,word_dim)\n",
    "        seq_len = x.size(-2)\n",
    "        p = self.crossAttention(x,c)\n",
    "        describe('p',p,self.debug)\n",
    "        h = x*p\n",
    "        describe('h',h,self.debug)\n",
    "        # p = (seq_len*seq_len): the attention of xi to xj\n",
    "        hi = self.Wsa1(h)\n",
    "        hj = self.Wsa2(h)\n",
    "        hi = hi.unsqueeze(-2)\n",
    "        hj = hj.unsqueeze(-3)\n",
    "        \n",
    "        #fcsa(xi,xj|c)\n",
    "        fcsa = hi+hj+self.bsa1\n",
    "        describe('fcsa',fcsa,self.debug)\n",
    "        fcsa = self.wsat(fcsa)\n",
    "        describe('w(fcsa)',fcsa,self.debug)\n",
    "        fcsa = torch.sigmoid(fcsa)\n",
    "        describe('sigmoid fcsa',fcsa,self.debug)\n",
    "        fcsa = fcsa.squeeze()\n",
    "        describe('squeeze(fcsa)',fcsa,self.debug)     \n",
    "        \n",
    "        # mask 對角\n",
    "        M = Variable(torch.eye(seq_len)).to(self.args.gpu).detach()\n",
    "        M[M==1]= float('-inf')\n",
    "        fcsa = fcsa+M\n",
    "        describe('fcsa+M',fcsa,self.debug)\n",
    "          \n",
    "            \n",
    "        fcsa = F.softmax(fcsa,dim=-1)  \n",
    "        describe('fcsa after sm',fcsa,self.debug)\n",
    "        \n",
    "        \n",
    "       \n",
    "        fcsa = fcsa.unsqueeze(-1)\n",
    "        describe('after pmatrix add one dim',fcsa,self.debug)\n",
    "        # fcsa (batch,sqlen,sqlen,fcsa(xi,xj))\n",
    "        # x (batch,1,sqlen,word_dim)\n",
    "        ui = fcsa*x.unsqueeze(1) \n",
    "        describe('unsqeeze x',x.unsqueeze(1),self.debug)\n",
    "        describe('ui=pMatrix*x',ui,self.debug)\n",
    "        ui = torch.sum(ui,1)\n",
    "        describe('ui after sum dim -1',ui,self.debug)   \n",
    "        ui = self.PFN(ui)\n",
    "        describe('ui after PFN',ui,self.debug)   \n",
    "        return  ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext.vocab import GloVe\n",
    "import torch\n",
    "import spacy\n",
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class getHotpotData():\n",
    "    def __init__(self,args,trainPath,devPath,):\n",
    "        self.nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'tagger'])   \n",
    "        self.trainpath= trainPath\n",
    "        self.devpath= devPath\n",
    "        \n",
    "        self.ANSWER  = data.Field(tokenize = self.tokenizer)\n",
    "        self.QUESTION = data.Field(tokenize = self.tokenizer)\n",
    "        self.CONTEXT = data.Field(tokenize = self.tokenizer)\n",
    "        fields = {'context':('Context', self.CONTEXT),'answer':('Answer', self.ANSWER),'question':('Question', self.QUESTION)}\n",
    "        \n",
    "        self.train = data.TabularDataset(path = self.trainpath,format='csv',fields=fields)\n",
    "        self.dev = data.TabularDataset(path = self.devpath,format='csv',fields=fields)\n",
    "        \n",
    "        self.CONTEXT.build_vocab(self.train, vectors=GloVe(name='6B', dim=300))  \n",
    "        self.QUESTION.build_vocab(self.train, vectors=GloVe(name='6B', dim=300)) \n",
    "        self.ANSWER.build_vocab(self.train, vectors=GloVe(name='6B', dim=300))\n",
    "        \n",
    "        self.train_iter = data.BucketIterator(dataset=self.train, batch_size=args.batch_size, shuffle=True, sort_within_batch=False, repeat=False)\n",
    "        self.dev_iter = data.BucketIterator(dataset=self.dev, batch_size=args.batch_size, shuffle=True, sort_within_batch=False, repeat=False)\n",
    "       \n",
    "        print('load hotpot data done')\n",
    "    def tokenizer(self,text):\n",
    "        return [str(token) for token in self.nlp(text)]\n",
    "    \n",
    "    def calculate_block_size(self, B):\n",
    "        data_lengths = []\n",
    "        for e in self.train.examples:\n",
    "            data_lengths.append(len(e.premise))\n",
    "            data_lengths.append(len(e.hypothesis))\n",
    "\n",
    "        mean = np.mean(data_lengths)\n",
    "        std = np.std(data_lengths)\n",
    "        self.block_size = int((2 * (std * ((2 * np.log(B)) ** (1/2)) + mean)) ** (1/3))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN4SNLI(customizedModule):\n",
    "    def __init__(self, args, data):\n",
    "        super(NN4SNLI, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        # set hyperparameters\n",
    "        # r: length of inner blocks\n",
    "        #self.args.r = self.args.block_size\n",
    "       # self.args.c = self.args.mSA_scalar\n",
    "\n",
    "        self.word_emb = nn.Embedding(len(data.CONTEXT.vocab.vectors), len(data.CONTEXT.vocab.vectors[0]))\n",
    "        # initialize word embedding with GloVe\n",
    "        self.word_emb.weight.data.copy_(data.CONTEXT.vocab.vectors)\n",
    "        # fine-tune the word embedding\n",
    "        self.word_emb.weight.requires_grad = True\n",
    "        # <unk> vectors is randomly initialized\n",
    "        nn.init.uniform(self.word_emb.weight.data[0], -0.05, 0.05)\n",
    "\n",
    "        self.csa = CSA(args,args.word_dim, args.word_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        c = self.word_emb(batch.Context)\n",
    "        q = self.word_emb(batch.Question)\n",
    "        describe('c',c,True)\n",
    "        describe('q',q,True)\n",
    "        x = self.csa(c,q)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load hotpot data done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\nlu\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch-size', default=32, type=int)\n",
    "parser.add_argument('--gpu', default=torch.device('cpu' if torch.cuda.is_available() else 'cpu'), type=int)\n",
    "parser.add_argument('--csa-mode',default='add',type = str)\n",
    "parser.add_argument('--word-dim',default=300,type = int)\n",
    "args = parser.parse_args(args=[])\n",
    "trainpath = 'C:/Users/User/Documents/3.NLP/Dataset/HotpotQA/small/smalltrain.csv'\n",
    "devpath = 'C:/Users/User/Documents/3.NLP/Dataset/HotpotQA/small/smalldev.csv'\n",
    "mydata = getHotpotData(args,devpath,devpath)\n",
    "model = NN4SNLI(args,mydata)\n",
    "print('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5e1bb92c502c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmydata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:==============================\n",
      "\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0181, -0.0628, -0.1345,  ..., -0.3822,  0.1050,  0.0631],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0747, -0.0400,  0.4423,  ..., -0.4493,  0.1235, -0.4446],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0013,  0.3651, -0.0774,  ..., -0.1836, -0.7652,  0.3921]],\n",
      "\n",
      "        [[-0.5258,  0.3754, -0.4145,  ..., -0.0208, -0.0290,  0.0780],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1749,  0.2296,  0.2492,  ..., -0.2413, -0.4040,  0.0547],\n",
      "         ...,\n",
      "         [-0.1686, -0.1958, -0.2025,  ..., -0.4990,  0.2265, -0.2899],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<EmbeddingBackward>) torch.Size([2258, 32, 300])\n",
      "==============================\n",
      "\n",
      "q:==============================\n",
      "\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2576, -0.0571, -0.6719,  ..., -0.1604,  0.0467, -0.0706],\n",
      "         [ 0.0567,  0.3712, -0.5279,  ..., -0.3131,  0.3742, -0.1407],\n",
      "         ...,\n",
      "         [ 0.0735,  0.2574,  0.2359,  ..., -0.4011, -0.5682, -0.4686],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.4598,  0.3532, -0.5286,  ..., -0.6118, -0.4584, -0.3514],\n",
      "         [-0.4762,  0.0695, -0.0131,  ..., -0.0502, -0.0759,  0.1486],\n",
      "         [-0.2097,  0.1807, -0.1640,  ..., -0.3359, -0.0595, -0.2864],\n",
      "         ...,\n",
      "         [ 0.0393,  0.1066, -0.4750,  ..., -0.1865, -0.0838,  0.3715],\n",
      "         [ 0.6947,  0.2218,  0.1053,  ...,  0.3487, -0.6308,  0.3809],\n",
      "         [-0.2223,  0.2386, -0.0480,  ..., -0.3270, -0.0537, -0.4182]],\n",
      "\n",
      "        [[-0.0769, -0.0212,  0.2127,  ...,  0.1835, -0.2918, -0.0465],\n",
      "         [ 0.6947,  0.2218,  0.1053,  ...,  0.3487, -0.6308,  0.3809],\n",
      "         [ 0.1270,  0.2106, -0.1898,  ..., -0.2849, -0.2937,  0.2436],\n",
      "         ...,\n",
      "         [-0.1537,  0.0430,  0.0336,  ..., -1.0232, -0.1833, -0.0961],\n",
      "         [-0.2106,  0.2268,  0.0637,  ..., -0.6105, -0.2069, -0.1013],\n",
      "         [ 0.0062,  1.0851, -0.1724,  ..., -0.3044,  0.2330, -0.4284]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<EmbeddingBackward>) torch.Size([32, 32, 300])\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2258) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fd9dbfbe7afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpresent_epoch\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-cce67ba15158>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-9595c7be4fc2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, c)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# x(batch,seq_len,word_dim) c(batch,word_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-8b17387d3706>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, q)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wq'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wx+wq'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bsa'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbsa\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wx+wq+bsa'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwq\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbsa\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2258) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "iterator = mydata.train_iter\n",
    "for i, batch in enumerate(iterator):\n",
    "    present_epoch = int(iterator.epoch)\n",
    "    if present_epoch > 10:\n",
    "        break\n",
    "    x = model(batch)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "+ self-attention\n",
    "+ S2T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class selfAttention(customizedModule):\n",
    "#    super(selfAttention,self):\n",
    "        \n",
    "#    def forward(x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
