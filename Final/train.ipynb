{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from models import CSATransformer\n",
    "from mydata import getHotpotData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixlabel(batch,dit):\n",
    "    #probality distribute \n",
    "    b = batch.Label.transpose(0,1) # batchsize*tensor\n",
    "    #print(b)\n",
    "    result = []\n",
    "    for index_tensor in b:\n",
    "        p = [0]*100\n",
    "        p_numpy = index_tensor.to('cpu').numpy()\n",
    "        for idx in p_numpy:    \n",
    "            act_idx = dit.itos[idx]\n",
    "            if act_idx=='<pad>':\n",
    "                break\n",
    "            p[int(act_idx)] = 1\n",
    "        result.append(torch.Tensor(p))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Hotpot data...\n",
      "training start!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'runs/13:38:55'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\tensorboardX\\record_writer.py\u001b[0m in \u001b[0;36mdirectory_check\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mfactory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mREGISTERED_FACTORIES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirectory_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'runs/13'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-10fbbc3e60c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-10fbbc3e60c6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training start!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-10fbbc3e60c6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, data)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'runs/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\tensorboardX\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, comment, purge_step, max_queue, flush_secs, filename_suffix, write_to_disk, log_dir, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;31m# and recreated later as needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;31m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\tensorboardX\\writer.py\u001b[0m in \u001b[0;36m_get_file_writer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m                                               \u001b[0mflush_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                                               \u001b[0mfilename_suffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename_suffix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                                               **self.kwargs)\n\u001b[0m\u001b[0;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\tensorboardX\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mlogdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         self.event_writer = EventFileWriter(\n\u001b[1;32m---> 94\u001b[1;33m             logdir, max_queue, flush_secs, filename_suffix)\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_logdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\tensorboardX\\event_file_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mdirectory_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQueue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         self._ev_writer = EventsWriter(os.path.join(\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\site-packages\\tensorboardX\\record_writer.py\u001b[0m in \u001b[0;36mdirectory_check\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlu\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'runs/13:38:55'"
     ]
    }
   ],
   "source": [
    "def train(args, data):\n",
    "    model = CSATransformer(args, data).to(args.gpu)\n",
    "   \n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.Adadelta(parameters, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    writer = SummaryWriter(log_dir='runs/' + args.model_time)\n",
    "\n",
    "    model.train()\n",
    "    loss, last_epoch = 0, -1\n",
    "    max_dev_acc, max_test_acc = 0, 0\n",
    "\n",
    "    iterator = data.train_iter\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        present_epoch = int(iterator.epoch)\n",
    "        if present_epoch == args.epoch:\n",
    "            break\n",
    "        if present_epoch > last_epoch:\n",
    "            print('epoch:', present_epoch + 1)\n",
    "        last_epoch = present_epoch\n",
    "        \n",
    "        #pred and label [tensor,tensor,tensor...]\n",
    "        pred = model(batch)\n",
    "        label = fixlabel( batch, data.LABEL.vocab)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for i in range(0,len(pred)):\n",
    "            x = pred[i]\n",
    "            y = label[i].narrow(0,x.size(0),0)\n",
    "            batch_loss = criterion(x,y)          \n",
    "            loss += batch_loss.data[0]  \n",
    "        loss/= args.batch_size\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % args.print_freq == 0:\n",
    "            dev_loss, dev_acc = test(model, data, mode='dev')\n",
    "            test_loss, test_acc = test(model, data)\n",
    "            c = (i + 1) // args.print_freq\n",
    "\n",
    "            writer.add_scalar('loss/train', loss, c)\n",
    "            writer.add_scalar('loss/dev', dev_loss, c)\n",
    "            writer.add_scalar('acc/dev', dev_acc, c)\n",
    "            writer.add_scalar('loss/test', test_loss, c)\n",
    "            writer.add_scalar('acc/test', test_acc, c)\n",
    "\n",
    "            print(f'train loss: {loss:.3f} / dev loss: {dev_loss:.3f} / test loss: {test_loss:.3f}'\n",
    "                  f' / dev acc: {dev_acc:.3f} / test acc: {test_acc:.3f}')\n",
    "\n",
    "            if dev_acc > max_dev_acc:\n",
    "                max_dev_acc = dev_acc\n",
    "                max_test_acc = test_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            loss = 0\n",
    "            model.train()\n",
    "\n",
    "    writer.close()\n",
    "    print(f'max dev acc: {max_dev_acc:.3f} / max test acc: {max_test_acc:.3f}')\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch-size', default=8, type=int)\n",
    "    parser.add_argument('--block-size', default=-1, type=int)\n",
    "    parser.add_argument('--data-type', default='hotpot')\n",
    "    parser.add_argument('--dropout', default=0.1, type=float)\n",
    "    parser.add_argument('--epoch', default=20, type=int)\n",
    "    parser.add_argument('--learning-rate', default=0.5, type=float)\n",
    "    parser.add_argument('--mSA-scalar', default=5.0, type=float)\n",
    "    parser.add_argument('--print-freq', default=3000, type=int)\n",
    "    parser.add_argument('--weight-decay', default=5e-5, type=float)\n",
    "    parser.add_argument('--word-dim', default=300, type=int)\n",
    "    parser.add_argument('--csa-mode',default='mul',type = str)\n",
    "    parser.add_argument('--gpu', default=torch.device('cpu' if torch.cuda.is_available() else 'cpu'), type=int)\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    print('loading Hotpot data...')\n",
    "    trainpath = './small_train_sep_100.csv'\n",
    "    devpath = './small_dev_sep_100.csv'\n",
    "    data = getHotpotData(args,trainpath,devpath)\n",
    "    \n",
    "    setattr(args, 'model_time', strftime('%H:%M:%S', gmtime()))\n",
    "    \n",
    "    print('training start!')\n",
    "    best_model = train(args, data)\n",
    "\n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')\n",
    "        \n",
    "    torch.save(best_model.state_dict(), f'saved_models/CSA_{args.data_type}_{args.model_time}.pt')\n",
    "\n",
    "    print('training finished!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
